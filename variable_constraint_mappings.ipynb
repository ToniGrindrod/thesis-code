{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "NXV2cPQuRbis",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NXV2cPQuRbis",
        "outputId": "1572fe61-fdb2-494a-fa7f-954e57f5126a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pypsa in /usr/local/lib/python3.12/dist-packages (0.35.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from pypsa) (2.0.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from pypsa) (1.16.1)\n",
            "Requirement already satisfied: pandas>=0.24 in /usr/local/lib/python3.12/dist-packages (from pypsa) (2.2.2)\n",
            "Requirement already satisfied: xarray in /usr/local/lib/python3.12/dist-packages (from pypsa) (2025.8.0)\n",
            "Requirement already satisfied: netcdf4 in /usr/local/lib/python3.12/dist-packages (from pypsa) (1.7.2)\n",
            "Requirement already satisfied: linopy>=0.4 in /usr/local/lib/python3.12/dist-packages (from pypsa) (0.5.5)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (from pypsa) (3.10.0)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.12/dist-packages (from pypsa) (5.24.1)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.12/dist-packages (from pypsa) (0.13.2)\n",
            "Requirement already satisfied: geopandas>=0.9 in /usr/local/lib/python3.12/dist-packages (from pypsa) (1.1.1)\n",
            "Requirement already satisfied: shapely<2.1 in /usr/local/lib/python3.12/dist-packages (from pypsa) (2.0.7)\n",
            "Requirement already satisfied: networkx>=2 in /usr/local/lib/python3.12/dist-packages (from pypsa) (3.5)\n",
            "Requirement already satisfied: deprecation in /usr/local/lib/python3.12/dist-packages (from pypsa) (2.1.0)\n",
            "Requirement already satisfied: validators in /usr/local/lib/python3.12/dist-packages (from pypsa) (0.35.0)\n",
            "Requirement already satisfied: highspy in /usr/local/lib/python3.12/dist-packages (from pypsa) (1.11.0)\n",
            "Requirement already satisfied: pyogrio>=0.7.2 in /usr/local/lib/python3.12/dist-packages (from geopandas>=0.9->pypsa) (0.11.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from geopandas>=0.9->pypsa) (25.0)\n",
            "Requirement already satisfied: pyproj>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from geopandas>=0.9->pypsa) (3.7.2)\n",
            "Requirement already satisfied: bottleneck in /usr/local/lib/python3.12/dist-packages (from linopy>=0.4->pypsa) (1.4.2)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.12/dist-packages (from linopy>=0.4->pypsa) (0.12.1)\n",
            "Requirement already satisfied: numexpr in /usr/local/lib/python3.12/dist-packages (from linopy>=0.4->pypsa) (2.11.0)\n",
            "Requirement already satisfied: dask>=0.18.0 in /usr/local/lib/python3.12/dist-packages (from linopy>=0.4->pypsa) (2025.5.0)\n",
            "Requirement already satisfied: polars in /usr/local/lib/python3.12/dist-packages (from linopy>=0.4->pypsa) (1.25.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from linopy>=0.4->pypsa) (4.67.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas>=0.24->pypsa) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=0.24->pypsa) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=0.24->pypsa) (2025.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->pypsa) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib->pypsa) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->pypsa) (4.59.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->pypsa) (1.4.9)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib->pypsa) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->pypsa) (3.2.3)\n",
            "Requirement already satisfied: cftime in /usr/local/lib/python3.12/dist-packages (from netcdf4->pypsa) (1.6.4.post1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from netcdf4->pypsa) (2025.8.3)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.12/dist-packages (from plotly->pypsa) (8.5.0)\n",
            "Requirement already satisfied: click>=8.1 in /usr/local/lib/python3.12/dist-packages (from dask>=0.18.0->linopy>=0.4->pypsa) (8.2.1)\n",
            "Requirement already satisfied: cloudpickle>=3.0.0 in /usr/local/lib/python3.12/dist-packages (from dask>=0.18.0->linopy>=0.4->pypsa) (3.1.1)\n",
            "Requirement already satisfied: fsspec>=2021.09.0 in /usr/local/lib/python3.12/dist-packages (from dask>=0.18.0->linopy>=0.4->pypsa) (2025.3.0)\n",
            "Requirement already satisfied: partd>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from dask>=0.18.0->linopy>=0.4->pypsa) (1.4.2)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.12/dist-packages (from dask>=0.18.0->linopy>=0.4->pypsa) (6.0.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas>=0.24->pypsa) (1.17.0)\n",
            "Requirement already satisfied: locket in /usr/local/lib/python3.12/dist-packages (from partd>=1.4.0->dask>=0.18.0->linopy>=0.4->pypsa) (1.0.0)\n",
            "Requirement already satisfied: ipdb in /usr/local/lib/python3.12/dist-packages (0.13.13)\n",
            "Requirement already satisfied: ipython>=7.31.1 in /usr/local/lib/python3.12/dist-packages (from ipdb) (7.34.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.12/dist-packages (from ipdb) (4.4.2)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.12/dist-packages (from ipython>=7.31.1->ipdb) (75.2.0)\n",
            "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.12/dist-packages (from ipython>=7.31.1->ipdb) (0.19.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.12/dist-packages (from ipython>=7.31.1->ipdb) (0.7.5)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.12/dist-packages (from ipython>=7.31.1->ipdb) (5.7.1)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from ipython>=7.31.1->ipdb) (3.0.51)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.12/dist-packages (from ipython>=7.31.1->ipdb) (2.19.2)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.12/dist-packages (from ipython>=7.31.1->ipdb) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.12/dist-packages (from ipython>=7.31.1->ipdb) (0.1.7)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.12/dist-packages (from ipython>=7.31.1->ipdb) (4.9.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.12/dist-packages (from jedi>=0.16->ipython>=7.31.1->ipdb) (0.8.4)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.12/dist-packages (from pexpect>4.3->ipython>=7.31.1->ipdb) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.12/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=7.31.1->ipdb) (0.2.13)\n"
          ]
        }
      ],
      "source": [
        "!pip install pypsa\n",
        "!pip install ipdb\n",
        "import ipdb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "5959066e",
      "metadata": {
        "id": "5959066e"
      },
      "outputs": [],
      "source": [
        "import pypsa\n",
        "import numpy as np\n",
        "import gc\n",
        "import pandas as pd\n",
        "import os\n",
        "import pickle\n",
        "from google.colab import drive\n",
        "import xarray as xr # Import xarray here\n",
        "\n",
        "# Define a simple, picklable representation for linear expressions\n",
        "class PicklableLinearExpr:\n",
        "    def __init__(self, vars, coeffs, const=0):\n",
        "        self.vars = vars\n",
        "        self.coeffs = coeffs\n",
        "        self.const = const\n",
        "\n",
        "    def __repr__(self):\n",
        "        terms = [f\"{coeff}*var_id_{var}\" for var, coeff in zip(self.vars, self.coeffs)]\n",
        "        expr_str = \" + \".join(terms)\n",
        "        if self.const != 0:\n",
        "            expr_str += f\" + {self.const}\"\n",
        "        return expr_str\n",
        "\n",
        "def fix_artificial_lines_hardcoded(network):\n",
        "    \"\"\"\n",
        "    Fix artificial lines with hardcoded values to match existing non-extendable lines:\n",
        "    - s_nom = 442.4 (your desired capacity)\n",
        "    - s_nom_extendable = False\n",
        "    - s_nom_min = 0\n",
        "    - s_nom_max = inf\n",
        "    - extendable = False (if column exists)\n",
        "    \"\"\"\n",
        "    print(\"=== FIXING ARTIFICIAL LINES WITH HARDCODED VALUES ===\")\n",
        "    fixed_capacity=442.4\n",
        "\n",
        "    # Find artificial lines\n",
        "    artificial_lines = [line for line in network.lines.index\n",
        "                       if any(keyword in str(line).lower() for keyword in ['new', '<->', 'artificial'])]\n",
        "\n",
        "    print(f\"Found {len(artificial_lines)} artificial lines to fix:\")\n",
        "\n",
        "    # Fix each artificial line with hardcoded values\n",
        "    for line_name in artificial_lines:\n",
        "        print(f\"\\nðŸ”§ Fixing: {line_name}\")\n",
        "\n",
        "        # s_nom = 442.4 (your fixed capacity)\n",
        "        old_s_nom = network.lines.loc[line_name, 's_nom']\n",
        "        network.lines.loc[line_name, 's_nom'] = fixed_capacity\n",
        "        print(f\"    s_nom: {old_s_nom} â†’ {fixed_capacity}\")\n",
        "\n",
        "        # s_nom_extendable = False\n",
        "        if 's_nom_extendable' not in network.lines.columns:\n",
        "            network.lines['s_nom_extendable'] = False\n",
        "        network.lines.loc[line_name, 's_nom_extendable'] = False\n",
        "        print(f\"    s_nom_extendable: â†’ False\")\n",
        "\n",
        "        # s_nom_min = 0\n",
        "        if 's_nom_min' not in network.lines.columns:\n",
        "            network.lines['s_nom_min'] = 0.0\n",
        "        network.lines.loc[line_name, 's_nom_min'] = 0.0\n",
        "        print(f\"    s_nom_min: â†’ 0.0\")\n",
        "\n",
        "        # s_nom_max = inf\n",
        "        if 's_nom_max' not in network.lines.columns:\n",
        "            network.lines['s_nom_max'] = float('inf')\n",
        "        network.lines.loc[line_name, 's_nom_max'] = float('inf')\n",
        "        print(f\"    s_nom_max: â†’ inf\")\n",
        "\n",
        "    return network\n",
        "\n",
        "def create_pypsa_network(network_file):\n",
        "    \"\"\"Create a PyPSA network from the .nc file.\"\"\"\n",
        "    # Initialize network\n",
        "    network = pypsa.Network(network_file)\n",
        "    for storage_name in network.storage_units.index:\n",
        "        # Use .loc for direct assignment to avoid SettingWithCopyWarning\n",
        "        network.storage_units.loc[storage_name, 'cyclic_state_of_charge'] = False\n",
        "\n",
        "    fix_artificial_lines_hardcoded(network)\n",
        "\n",
        "    return network\n",
        "\n",
        "def _variable_mapping(network_file):\n",
        "    \"\"\"\n",
        "    Create a mapping from variable IDs to variable names.\n",
        "\n",
        "    Parameters:\n",
        "    -----------\n",
        "    network_file : str\n",
        "        Path to the PyPSA network file\n",
        "\n",
        "    Returns:\n",
        "    --------\n",
        "    dict : var_id_to_name - Mapping from variable IDs to variable names\n",
        "    \"\"\"\n",
        "    print(\"Starting variable ID mapping\")\n",
        "    network = create_pypsa_network(network_file)\n",
        "    # Create model once - this is an expensive operation\n",
        "    temp_model = network.optimize.create_model()\n",
        "    obj_expr = temp_model.objective\n",
        "    objective_vars = obj_expr.vars.copy()\n",
        "    vars_flat = objective_vars.values.flatten()\n",
        "\n",
        "    # Create variable ID to name mapping\n",
        "    var_id_to_name = {}\n",
        "    for var_name, variable in temp_model.variables.items():\n",
        "        # Get the variable labels (IDs) for this variable\n",
        "        var_labels = variable.labels\n",
        "\n",
        "        if hasattr(var_labels, 'values'):\n",
        "            # Multi-dimensional variable\n",
        "            labels_flat = var_labels.values.flatten()\n",
        "            coords = variable.labels.coords\n",
        "            for i, label in enumerate(labels_flat):\n",
        "                if label != -1:  # -1 means no variable\n",
        "                    # Create a name that includes the index for multi-dim variables\n",
        "                    if len(coords) > 0:\n",
        "                        # Get the coordinate values for this flat index\n",
        "                        unravel_idx = np.unravel_index(i, var_labels.shape)\n",
        "                        coord_values = []\n",
        "                        for dim_idx, dim_name in enumerate(var_labels.dims):\n",
        "                            coord_val = coords[dim_name].values[unravel_idx[dim_idx]]\n",
        "\n",
        "                            # Handle datetime64 values properly\n",
        "                            if isinstance(coord_val, np.datetime64) or hasattr(coord_val, 'strftime'):\n",
        "                                # Convert datetime to string in ISO format\n",
        "                                try:\n",
        "                                    coord_val = pd.Timestamp(coord_val).isoformat()\n",
        "                                except:\n",
        "                                    # Fallback if conversion fails\n",
        "                                    coord_val = str(coord_val)\n",
        "\n",
        "                            coord_values.append(f\"{dim_name}={coord_val}\")\n",
        "\n",
        "                        full_name = f\"{var_name}[{','.join(coord_values)}]\"\n",
        "                    else:\n",
        "                        full_name = f\"{var_name}[{i}]\"\n",
        "                    var_id_to_name[label] = full_name\n",
        "        else:\n",
        "            # Scalar variable\n",
        "            var_id_to_name[var_labels] = var_name\n",
        "\n",
        "    variable_names_dict={}\n",
        "    var_indices_dict={}\n",
        "\n",
        "    for snapshot in network.snapshots:\n",
        "        # Convert to ISO format for consistent formatting with variable names\n",
        "        snapshot_iso = pd.Timestamp(snapshot).isoformat()\n",
        "        variable_names_dict[snapshot_iso] = []\n",
        "        var_indices_dict[snapshot_iso] = []\n",
        "\n",
        "    # Filter variables to only include those from the current snapshot\n",
        "    for i, var_id in enumerate(vars_flat):\n",
        "        if var_id != -1 and var_id in var_id_to_name:\n",
        "            var_name = var_id_to_name[var_id]\n",
        "\n",
        "            if 'snapshot=' in var_name:\n",
        "                # Extract the snapshot value from the variable name\n",
        "                snapshot_part = var_name.split('snapshot=')[1].split(',')[0].split(']')[0]\n",
        "                variable_names_dict[snapshot_part].append(var_name)\n",
        "                var_indices_dict[snapshot_part].append(i)\n",
        "            else:\n",
        "                # Include variables without snapshot dimension (like investment variables)\n",
        "                variable_names_dict[snapshot_part].append(var_name)\n",
        "                var_indices_dict[snapshot_part].append(i)\n",
        "\n",
        "\n",
        "    return variable_names_dict, var_indices_dict\n",
        "\n",
        "def save_dictionary(snapshot_dict, dict_name, network_file, output_dir=\"snapshot_dicts\"):\n",
        "    \"\"\"\n",
        "    Save the variable ID to name mapping to a file.\n",
        "\n",
        "    Parameters:\n",
        "    -----------\n",
        "    snapshot_dict : dict\n",
        "        Mapping from snapshots to list of variable name (variable_names_dict) or list of variable indices (var_indices_dict)\n",
        "    dict_name : str\n",
        "        Name of type of the dictionary to save (variable_names_dict or var_indices_dict)\n",
        "    network_file : str\n",
        "        Path to the network file used to create the mapping\n",
        "    output_dir : str, optional\n",
        "        Directory to save the mapping file to\n",
        "\n",
        "    Returns:\n",
        "    --------\n",
        "    str : Path to the saved mapping file\n",
        "    \"\"\"\n",
        "    # Handle Google Drive if needed\n",
        "    if '/content/drive' in output_dir:\n",
        "        try:\n",
        "            from google.colab import drive\n",
        "            drive.mount('/content/drive')\n",
        "        except ImportError:\n",
        "            pass  # Not in Colab environment\n",
        "\n",
        "    # Create output directory if it doesn't exist\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "    # Get the network filename without path or extension\n",
        "    network_name = os.path.basename(network_file)\n",
        "    network_name = os.path.splitext(network_name)[0]\n",
        "\n",
        "    # Create output filename\n",
        "    var_map_file = os.path.join(output_dir, f\"{network_name}_{dict_name}.pkl\")\n",
        "\n",
        "    # Save mapping to file\n",
        "    with open(var_map_file, 'wb') as f:\n",
        "        pickle.dump(snapshot_dict, f)\n",
        "\n",
        "    print(f\"Saved variable mapping to: {var_map_file}\")\n",
        "\n",
        "    return var_map_file\n",
        "\n",
        "def load_dictionary(network_file, dict_name,input_dir=\"snapshot_dicts\"):\n",
        "    \"\"\"\n",
        "    Load previously saved variable ID to name mapping from a file.\n",
        "\n",
        "    Parameters:\n",
        "    -----------\n",
        "    network_file : str\n",
        "        Path to the network file used to create the mapping\n",
        "    input_dir : str, optional\n",
        "        Directory where the mapping file is stored\n",
        "\n",
        "    Returns:\n",
        "    --------\n",
        "    dict : var_id_to_name - The loaded variable ID to name mapping\n",
        "    \"\"\"\n",
        "    # Handle Google Drive if needed\n",
        "    if '/content/drive' in input_dir:\n",
        "        try:\n",
        "            from google.colab import drive\n",
        "            drive.mount('/content/drive')\n",
        "        except ImportError:\n",
        "            pass  # Not in Colab environment\n",
        "\n",
        "    # Get the network filename without path or extension\n",
        "    network_name = os.path.basename(network_file)\n",
        "    network_name = os.path.splitext(network_name)[0]\n",
        "\n",
        "    # Create input filename\n",
        "    var_map_file = os.path.join(input_dir, f\"{network_name}_{dict_name}.pkl\")\n",
        "\n",
        "    # Check if file exists\n",
        "    if not os.path.exists(var_map_file):\n",
        "        raise FileNotFoundError(f\"Variable mapping file for {network_name} not found in {input_dir}\")\n",
        "\n",
        "    # Load mapping from file\n",
        "    with open(var_map_file, 'rb') as f:\n",
        "        var_id_to_name = pickle.load(f)\n",
        "\n",
        "    print(f\"Loaded variable mapping from: {var_map_file}\")\n",
        "\n",
        "    return var_id_to_name"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "44c253e4",
      "metadata": {
        "id": "44c253e4"
      },
      "outputs": [],
      "source": [
        "def main():\n",
        "    # Example usage\n",
        "    try:\n",
        "        from google.colab import drive\n",
        "        drive.mount('/content/drive')\n",
        "        network_file = \"/content/drive/MyDrive/Colab_Notebooks/networks_1_year_connected/elec_s_10_ec_lc1.0_1h.nc\"\n",
        "    except ImportError:\n",
        "        # Not in Colab environment, use local path\n",
        "        network_file = \"path/to/your/local/network_file.nc\"  # Update this to your local path\n",
        "\n",
        "    # Define output directory\n",
        "    output_dir = \"/content/drive/MyDrive/Colab_Notebooks/snapshot_dicts\"\n",
        "\n",
        "    # Create variable ID to name mapping\n",
        "    variable_names_dict, var_indices_dict = _variable_mapping(network_file)\n",
        "\n",
        "    # Save mapping\n",
        "    var_names_file = save_dictionary(variable_names_dict, \"variable_names_dict\", network_file, output_dir)\n",
        "    var_indices_file = save_dictionary(var_indices_dict, \"var_indices_dict\", network_file, output_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "kASMIIT_RpD6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kASMIIT_RpD6",
        "outputId": "60a4d7ab-8c5a-4e8d-d801-db5294713c6e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Starting variable ID mapping\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:pypsa.network.io:Importing network from PyPSA version v0.0.0 while current version is v0.35.2. Read the release notes at https://pypsa.readthedocs.io/en/latest/release_notes.html to prepare your network for import.\n",
            "WARNING:pypsa.consistency:The following buses have carriers which are not defined:\n",
            "Index(['ZA0 0', 'ZA0 1', 'ZA0 2', 'ZA0 3', 'ZA0 4', 'ZA0 5', 'ZA0 6', 'ZA0 7',\n",
            "       'ZA0 8', 'ZA0 9', 'ZA1 0', 'ZA2 0', 'ZA3 0'],\n",
            "      dtype='object', name='Bus')\n",
            "WARNING:pypsa.consistency:The following lines have carriers which are not defined:\n",
            "Index(['0', '1', '10', '11', '12', '13', '14', '15', '2', '3', '4', '5', '6',\n",
            "       '7', '8', '9', 'lines new ZA0 4 <-> ZA2 0 AC',\n",
            "       'lines new ZA0 0 <-> ZA1 0 AC', 'lines new ZA0 0 <-> ZA3 0 AC'],\n",
            "      dtype='object', name='Line')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== FIXING ARTIFICIAL LINES WITH HARDCODED VALUES ===\n",
            "Found 3 artificial lines to fix:\n",
            "\n",
            "ðŸ”§ Fixing: lines new ZA0 4 <-> ZA2 0 AC\n",
            "    s_nom: 0.0 â†’ 442.4\n",
            "    s_nom_extendable: â†’ False\n",
            "    s_nom_min: â†’ 0.0\n",
            "    s_nom_max: â†’ inf\n",
            "\n",
            "ðŸ”§ Fixing: lines new ZA0 0 <-> ZA1 0 AC\n",
            "    s_nom: 0.0 â†’ 442.4\n",
            "    s_nom_extendable: â†’ False\n",
            "    s_nom_min: â†’ 0.0\n",
            "    s_nom_max: â†’ inf\n",
            "\n",
            "ðŸ”§ Fixing: lines new ZA0 0 <-> ZA3 0 AC\n",
            "    s_nom: 0.0 â†’ 442.4\n",
            "    s_nom_extendable: â†’ False\n",
            "    s_nom_min: â†’ 0.0\n",
            "    s_nom_max: â†’ inf\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/linopy/expressions.py:1861: FutureWarning:\n",
            "\n",
            "In a future version of xarray the default value for join will change from join='outer' to join='exact'. This change will result in the following ValueError: cannot be aligned with join='exact' because index/labels/sizes are not equal along these coordinates (dimensions): '_term' ('_term',) The recommendation is to set join explicitly for this case.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Saved variable mapping to: /content/drive/MyDrive/Colab_Notebooks/snapshot_dicts/elec_s_10_ec_lc1.0_1h_variable_names_dict.pkl\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Saved variable mapping to: /content/drive/MyDrive/Colab_Notebooks/snapshot_dicts/elec_s_10_ec_lc1.0_1h_var_indices_dict.pkl\n"
          ]
        }
      ],
      "source": [
        "main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "qf2QxV5H_99m",
      "metadata": {
        "id": "qf2QxV5H_99m"
      },
      "outputs": [],
      "source": [
        "# drive.mount('/content/drive')\n",
        "# network_file = \"/content/drive/MyDrive/Colab_Notebooks/networks_1_year_connected/elec_s_10_ec_lc1.0_1h.nc\"\n",
        "# network = create_pypsa_network(network_file)\n",
        "# # Create model once - this is an expensive operation\n",
        "# temp_model = network.optimize.create_model()\n",
        "\n",
        "# for name, constraint_group in temp_model.constraints.items():\n",
        "#     print(name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "4HzCyfCXf40z",
      "metadata": {
        "id": "4HzCyfCXf40z"
      },
      "outputs": [],
      "source": [
        "# network.lines['s_max_pu']"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "pypsa-earth-rl",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}